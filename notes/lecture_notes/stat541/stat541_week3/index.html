
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../stat541_week2/">
      
      
        <link rel="next" href="../stat541_assignment1/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>Week3 - Homepage</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      

  
  
  
  
  <style>:root{--md-annotation-icon:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2024%2024%22%3E%3Cpath%20d%3D%22M22%2012a10%2010%200%200%201-10%2010A10%2010%200%200%201%202%2012%2010%2010%200%200%201%2012%202a10%2010%200%200%201%2010%2010m-12%206%206-6-6-6-1.4%201.4%204.6%204.6-4.6%204.6z%22/%3E%3C/svg%3E');}</style>


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#week3" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Homepage" class="md-header__button md-logo" aria-label="Homepage" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Homepage
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Week3
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="blue-grey" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="blue-grey" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Homepage" class="md-nav__button md-logo" aria-label="Homepage" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Homepage
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../academic_profile/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Academic Background
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Notes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Lecture Notes
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Lecture Notes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1_1" id="__nav_3_1_1_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    CMPUT 501 Advanced Algorithms
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_1">
            <span class="md-nav__icon md-icon"></span>
            CMPUT 501 Advanced Algorithms
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture7/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture7
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture8
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture9/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../cmput501/lecture10/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Lecture10
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_2" >
        
          
          <label class="md-nav__link" for="__nav_3_1_2" id="__nav_3_1_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    MATH 515 Mathematical Finance I
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1_2">
            <span class="md-nav__icon md-icon"></span>
            MATH 515 Mathematical Finance I
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math515_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../math515_week1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week1-2
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_1_3" id="__nav_3_1_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    STAT 541 Statistics for Leaning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_1_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_1_3">
            <span class="md-nav__icon md-icon"></span>
            STAT 541 Statistics for Leaning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_intro/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Week3
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Week3
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#recap-on-singular-value-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Recap on Singular Value Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recap on Singular Value Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonal-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Orthogonal Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thin-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Thin SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-svd" class="md-nav__link">
    <span class="md-ellipsis">
      General SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spectral-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Spectral Decomposition
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recap-on-multivariate-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Recap on Multivariate Statistics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recap on Multivariate Statistics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#notations" class="md-nav__link">
    <span class="md-ellipsis">
      Notations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multivariate-normal-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Multivariate Normal Distribution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Regression
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rewrite-training-data-in-matrix-form" class="md-nav__link">
    <span class="md-ellipsis">
      Rewrite Training Data in Matrix Form
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recap-on-likelihood-function" class="md-nav__link">
    <span class="md-ellipsis">
      Recap on Likelihood Function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimate-the-coefficients-beta_i" class="md-nav__link">
    <span class="md-ellipsis">
      Estimate the Coefficients \(\beta_i\)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate-ols-prediction-estimate" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluate OLS Prediction Estimate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interval-estimate" class="md-nav__link">
    <span class="md-ellipsis">
      Interval Estimate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#examples-and-discrete-features" class="md-nav__link">
    <span class="md-ellipsis">
      Examples and Discrete Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variable-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Variable Selection
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_assignment1/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignment 1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_assignment2/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignment 2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week6/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week6
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week8/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week8
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_assignment3/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignment 3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week9/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week9
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week10/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week10
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week11/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week11
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_assignment4/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignment 4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week12/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week12
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_week13/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Week13
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stat541_assignment5/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Assignment 5
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../naming_conventions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../r_objects/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    R
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Comparison Theorems in Riemann Geometry
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            Comparison Theorems in Riemann Geometry
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../comparison_thm/preliminaries/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Preliminaries to Comparison Theorems
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../comparison_thm/comp_thm/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comparison Theorem
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../comparison_thm/comp_thm_app/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comparison Theorems and Application
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_5" >
        
          
          <label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Hermitian Metric
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_5">
            <span class="md-nav__icon md-icon"></span>
            Hermitian Metric
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../hermitian_metric/readme/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hermitian Metric
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../laplacian_kahler_mfd/readme/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Laplacian Operator
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Miscellaneous
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Miscellaneous
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../suggestions/creditcardcomp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Compare Credit Cards
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../suggestions/acrobatbookmark/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Acrobat 自动添加书签
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#recap-on-singular-value-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Recap on Singular Value Decomposition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recap on Singular Value Decomposition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#orthogonal-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Orthogonal Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#thin-svd" class="md-nav__link">
    <span class="md-ellipsis">
      Thin SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#general-svd" class="md-nav__link">
    <span class="md-ellipsis">
      General SVD
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#spectral-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Spectral Decomposition
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recap-on-multivariate-statistics" class="md-nav__link">
    <span class="md-ellipsis">
      Recap on Multivariate Statistics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Recap on Multivariate Statistics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#notations" class="md-nav__link">
    <span class="md-ellipsis">
      Notations
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multivariate-normal-distribution" class="md-nav__link">
    <span class="md-ellipsis">
      Multivariate Normal Distribution
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Regression
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#rewrite-training-data-in-matrix-form" class="md-nav__link">
    <span class="md-ellipsis">
      Rewrite Training Data in Matrix Form
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recap-on-likelihood-function" class="md-nav__link">
    <span class="md-ellipsis">
      Recap on Likelihood Function
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#estimate-the-coefficients-beta_i" class="md-nav__link">
    <span class="md-ellipsis">
      Estimate the Coefficients \(\beta_i\)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#evaluate-ols-prediction-estimate" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluate OLS Prediction Estimate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#interval-estimate" class="md-nav__link">
    <span class="md-ellipsis">
      Interval Estimate
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#examples-and-discrete-features" class="md-nav__link">
    <span class="md-ellipsis">
      Examples and Discrete Features
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#variable-selection" class="md-nav__link">
    <span class="md-ellipsis">
      Variable Selection
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="week3">Week3<a class="headerlink" href="#week3" title="Permanent link">&para;</a></h1>
<h2 id="recap-on-singular-value-decomposition">Recap on Singular Value Decomposition<a class="headerlink" href="#recap-on-singular-value-decomposition" title="Permanent link">&para;</a></h2>
<h3 id="orthogonal-matrix">Orthogonal Matrix<a class="headerlink" href="#orthogonal-matrix" title="Permanent link">&para;</a></h3>
<p>Let <span class="arithmatex">\(V\in \mathbb{R}^{p\times k}\)</span>, given by</p>
<div class="arithmatex">\[
V = \begin{bmatrix}
\mid &amp; &amp; \mid \\
v_1 &amp; \cdots &amp; v_k \\
\mid &amp; &amp; \mid
\end{bmatrix}.
\]</div>
<p>Then <span class="arithmatex">\(V\)</span> has orthogonal columns if</p>
<div class="arithmatex">\[
v_i^T v_j =\left\{\begin{matrix}
    &amp;  1, \quad \text{ if } i=j, \\
    &amp;  0, \quad \text{ if } i\neq j. 
\end{matrix}\right.
\]</div>
<p>For such <span class="arithmatex">\(V\)</span>, we have <span class="arithmatex">\(V^T V = I_k\)</span>. Note that it is often NOT the case that <span class="arithmatex">\(V V^T = I_p\)</span>.</p>
<p>A square matrix <span class="arithmatex">\(V\in \mathbb{R}^{k\times k}\)</span> with orthogonal columns is called an orthogonal matrix. Note that <span class="arithmatex">\(V^{-1} = V^T\)</span>.</p>
<h3 id="thin-svd">Thin SVD<a class="headerlink" href="#thin-svd" title="Permanent link">&para;</a></h3>
<p>For a matrix <span class="arithmatex">\(A\in \mathbb{R}^{m\times n}\)</span> (<span class="arithmatex">\(m\geq n\)</span>), whose rank is <span class="arithmatex">\(r\)</span>.The thin SVD of <span class="arithmatex">\(A\)</span> is a representation of the form</p>
<div class="arithmatex">\[
A = U \Sigma V^{T}, \quad U\in \mathbb{R}^{m\times n}, \Sigma\in \mathbb{R}^{n\times n}, V\in \mathbb{R}^{n\times n},
\]</div>
<p>where <span class="arithmatex">\(U,V\)</span> have normal orthogonal columns, and <span class="arithmatex">\(\Sigma\)</span> is diagonal with the first <span class="arithmatex">\(r\)</span> values <span class="arithmatex">\(\sigma_1 \geq \dots \geq \sigma_r&gt;0\)</span>, where <span class="arithmatex">\(\sigma_i\)</span> is the length of <span class="arithmatex">\(A\boldsymbol{v}_i\)</span>. </p>
<p>The column vectors of <span class="arithmatex">\(U\)</span> and <span class="arithmatex">\(V\)</span> are respectively called the left and right singular vectors. The singular values of <span class="arithmatex">\(A\)</span> are the diagonal elements of <span class="arithmatex">\(\Sigma\)</span>.</p>
<p><strong>Remarkable results</strong>: Every matrix <span class="arithmatex">\(A\in \mathbb{R}^{m\times n}\)</span> has an SVD.</p>
<h3 id="general-svd">General SVD<a class="headerlink" href="#general-svd" title="Permanent link">&para;</a></h3>
<p>We consider the singular vectors: the <span class="arithmatex">\(\boldsymbol{u}\)</span>'s and <span class="arithmatex">\(\boldsymbol{v}\)</span>'s give bases for the four fundamental subspaces:</p>
<ul>
<li><span class="arithmatex">\(\boldsymbol{u}_1, \dots, \boldsymbol{u}_r \quad\)</span> is an orthonormal basis for the column space</li>
<li><span class="arithmatex">\(\boldsymbol{u}_{r+1}, \dots, \boldsymbol{u}_m\)</span> is an orthonormal basis for the left nullspace <span class="arithmatex">\(\boldsymbol{N}\left(A^T\right)\)</span></li>
<li><span class="arithmatex">\(\boldsymbol{v}_1, \dots, \boldsymbol{v}_r \quad\)</span> is an orthonormal basis for the row space</li>
<li><span class="arithmatex">\(\boldsymbol{v}_{r+1}, \dots, \boldsymbol{v}_n\)</span> is an orthonormal basis for the nullspace <span class="arithmatex">\(\boldsymbol{N}(A)\)</span>.</li>
</ul>
<p>More than just orthogonality, these basis vectors diagonalize the matrix <span class="arithmatex">\(A\)</span> :</p>
<div class="arithmatex">\[
A \boldsymbol{v}_1=\sigma_1 \boldsymbol{u}_1,\quad A \boldsymbol{v}_2=\sigma_2 \boldsymbol{u}_2,\quad \dots,\quad A \boldsymbol{v}_r=\sigma_r \boldsymbol{u}_r.
\]</div>
<p>Those singular values <span class="arithmatex">\(\sigma_1\)</span> to <span class="arithmatex">\(\sigma_r\)</span> will be positive numbers: <span class="arithmatex">\(\sigma_i\)</span> is the length of <span class="arithmatex">\(A \boldsymbol{v}_i\)</span>. The <span class="arithmatex">\(\sigma\)</span>'s go into a diagonal matrix that is otherwise zero. That matrix is <span class="arithmatex">\(\Sigma\)</span>. </p>
<p>Then the equations <span class="arithmatex">\(A \boldsymbol{v}_i=\sigma_i \boldsymbol{u}_i\)</span> tell us column by column that <span class="arithmatex">\(\boldsymbol{A} \boldsymbol{V}_{\boldsymbol{r}}=\boldsymbol{U}_{\boldsymbol{r}} \boldsymbol{\Sigma}_{\boldsymbol{r}}\)</span> :</p>
<div class="arithmatex">\[
A\begin{bmatrix}\boldsymbol{v}_1 \cdots \boldsymbol{v}_r\end{bmatrix}=\begin{bmatrix}
\boldsymbol{u}_1, \dots, \boldsymbol{u}_r
\end{bmatrix}\begin{bmatrix}
\sigma_1 &amp; &amp; \\
&amp; \ddots &amp; \\
&amp; &amp; \sigma_r
\end{bmatrix}.
\]</div>
<p>Those <span class="arithmatex">\(\boldsymbol{v}\)</span>'s and <span class="arithmatex">\(\boldsymbol{u}\)</span>'s account for the row space and column space of <span class="arithmatex">\(A\)</span>. We have <span class="arithmatex">\(n-r\)</span> more <span class="arithmatex">\(\boldsymbol{v}\)</span>'s and <span class="arithmatex">\(m-r\)</span> more <span class="arithmatex">\(\boldsymbol{u}\)</span>'s, from the nullspace <span class="arithmatex">\(\boldsymbol{N}(A)\)</span> and the left nullspace <span class="arithmatex">\(\boldsymbol{N}\left(A^T\right)\)</span>. They are automatically orthogonal to the first <span class="arithmatex">\(\boldsymbol{v}\)</span>'s and <span class="arithmatex">\(\boldsymbol{u}\)</span>'s. We now include all the <span class="arithmatex">\(\boldsymbol{v}\)</span>'s and <span class="arithmatex">\(\boldsymbol{u}\)</span>'s in <span class="arithmatex">\(V\)</span> and <span class="arithmatex">\(U\)</span>, so these matrices become square. We still have <span class="arithmatex">\(\boldsymbol{A} \boldsymbol{V}=\boldsymbol{U} \boldsymbol{\Sigma}\)</span>:</p>
<div class="arithmatex">\[
A\begin{bmatrix}\boldsymbol{v}_1, \dots, \boldsymbol{v}_r, \dots, \boldsymbol{v}_n\end{bmatrix}=\begin{bmatrix}\boldsymbol{u}_1, \dots, \boldsymbol{u}_r, \dots, \boldsymbol{u}_m\end{bmatrix}
\begin{bmatrix}
\Sigma_r &amp; &amp; &amp; \\
&amp; 0 &amp; &amp; \\
&amp; &amp; \ddots &amp; 
\end{bmatrix}.
\]</div>
<p>The new <span class="arithmatex">\(\Sigma\)</span> is <span class="arithmatex">\(m\times n\)</span>. It is just the <span class="arithmatex">\(r\times r\)</span> matrix <span class="arithmatex">\(\Sigma_r\)</span> with <span class="arithmatex">\(m-r\)</span> extra zero rows and <span class="arithmatex">\(n-r\)</span> new zero columns. The real change is in the shapes of <span class="arithmatex">\(U\)</span> and <span class="arithmatex">\(V\)</span>. Those are square orthogonal matrices. So <span class="arithmatex">\(A V=U \Sigma\)</span> can become <span class="arithmatex">\(\boldsymbol{A}=\boldsymbol{U} \boldsymbol{\Sigma} \boldsymbol{V}^{\mathbf{T}}\)</span>. This is the Singular Value Decomposition. I can multiply columns <span class="arithmatex">\(\boldsymbol{u}_i \sigma_i\)</span> from <span class="arithmatex">\(U \Sigma\)</span> by rows of <span class="arithmatex">\(V^{T}\)</span>:</p>
<div class="arithmatex">\[
A=U \Sigma V^{T}=u_1 \sigma_1 v_1^{T}+\cdots+u_r \sigma_r v_r^{T}.
\]</div>
<p class="annotate">Each <span class="arithmatex">\(\sigma_i^2\)</span> is an eigenvalue of <span class="arithmatex">\(A^T A\)</span>(1) and also <span class="arithmatex">\(A A^{T}\)</span>(2). When we put the singular values in descending order(3), <span class="arithmatex">\(\sigma_1 \geq \sigma_2 \geq \dots \sigma_r&gt;0\)</span>, the above splitting gives the <span class="arithmatex">\(r\)</span> rank-one pieces of <span class="arithmatex">\(A\)</span> in order of importance. Then <span class="arithmatex">\(\sigma_1\)</span> is the maximum of the ratio: </p>
<ol>
<li>with <span class="arithmatex">\(\boldsymbol{v}\)</span>'s as orthonormal eigenvectors</li>
<li>with <span class="arithmatex">\(\boldsymbol{u}\)</span>'s as orthonormal eigenvectors</li>
<li>For a matrix <span class="arithmatex">\(A\in \mathbb{R}^{m\times n}\)</span>, we can define a column swapping matrix <span class="arithmatex">\(P_{i,j}\in \mathbb{R}^{n\times n}\)</span>, which swaps the <span class="arithmatex">\(i\)</span>-th column and <span class="arithmatex">\(j\)</span>-th column of <span class="arithmatex">\(A\)</span> by right multiplication, i.e. <span class="arithmatex">\(AP_{i,j}\)</span>. Using <span class="arithmatex">\(P_{i,j}\)</span>, we can swap the positions of <span class="arithmatex">\(i\)</span>-th singular value and <span class="arithmatex">\(j\)</span>-th singular value of <span class="arithmatex">\(\Sigma\)</span>: <span class="arithmatex">\(U\Sigma V^T = \left(UP_{i,j}\right) \left(P_{i,j}^T \Sigma P_{i,j}\right) \left(V P_{i,j}\right)^T\)</span>. 
The column swapping matrix <span class="arithmatex">\(P_{i,j}\)</span> has the following properties: (let <span class="arithmatex">\(A\)</span> have rows <span class="arithmatex">\(v_i\)</span>, <span class="arithmatex">\(i=1,\dots, m\)</span> and columns <span class="arithmatex">\(w_j\)</span>, <span class="arithmatex">\(j=1,\dots,n\)</span>)<ul>
<li><span class="arithmatex">\(AP_{i,j}\)</span>: <span class="arithmatex">\(v_i \leftrightarrow v_j\)</span>. </li>
<li><span class="arithmatex">\(P_{i,j}^T A = \left(A^TP_{i,j}\right)^T\)</span>: <span class="arithmatex">\(w_i \leftrightarrow w_j\)</span>. </li>
<li><span class="arithmatex">\(P_{i,j}^T P_{i,j} = I\)</span>. </li>
<li><span class="arithmatex">\(P_{i,j} P_{i,j}^T = P_{i,j}^T P_{i,j} P_{i,j} P_{i,j}^T = I\)</span>. </li>
</ul>
</li>
</ol>
<div class="arithmatex">\[
\max_{\|x\| = 1}\frac{\|A \boldsymbol{x}\|}{\|\boldsymbol{x}\|}.
\]</div>
<h3 id="spectral-decomposition">Spectral Decomposition<a class="headerlink" href="#spectral-decomposition" title="Permanent link">&para;</a></h3>
<p>A spectral decomposition of a symmetric matrix <span class="arithmatex">\(A\in \mathbb{R}^{n\times n}\)</span> is a representation of <span class="arithmatex">\(A\)</span> as</p>
<div class="arithmatex">\[
A = VDV^T, \quad V\in \mathbb{R}^{n\times n}, D\in \mathbb{R}^{n\times n},
\]</div>
<p>where <span class="arithmatex">\(V = \begin{bmatrix}v_1, v_2, \dots, v_n \end{bmatrix}\)</span> is orthogonal and <span class="arithmatex">\(D = {\rm diag}\{d_1,d_2,\dots,d_n\}\)</span> is diagonal.</p>
<p>The columns of <span class="arithmatex">\(V\)</span> are the eigenvector of <span class="arithmatex">\(A\)</span> and <span class="arithmatex">\(d_i\)</span> is the associated eigenvalue:</p>
<div class="arithmatex">\[
Av_i = VDV^Tv_i = d_i v_i.
\]</div>
<p><strong>Remarkable results</strong> (spectral theorem): Every symmetric matrix <span class="arithmatex">\(A\in \mathbb{R}^{n\times n}\)</span> has a spectral decomposition.</p>
<h2 id="recap-on-multivariate-statistics">Recap on Multivariate Statistics<a class="headerlink" href="#recap-on-multivariate-statistics" title="Permanent link">&para;</a></h2>
<h3 id="notations">Notations<a class="headerlink" href="#notations" title="Permanent link">&para;</a></h3>
<p>Let <span class="arithmatex">\(\boldsymbol{X}\)</span> be a <span class="arithmatex">\(k\)</span>-dimensional random vector (a special case of random matrices)</p>
<div class="arithmatex">\[
\boldsymbol{X}= \begin{bmatrix} 
X_1 \\
\vdots \\
X_k
\end{bmatrix},
\]</div>
<p>or a <span class="arithmatex">\(p\times q\)</span> random matrix</p>
<div class="arithmatex">\[
\boldsymbol{X}= \begin{bmatrix}
X_{11} &amp;\cdots &amp; X_{1q} \\
\vdots &amp; \ddots &amp; \vdots \\
X_{p1} &amp; \cdots &amp; X_{pq}
\end{bmatrix},
\]</div>
<p>where each <span class="arithmatex">\(X_i\in\)</span> or <span class="arithmatex">\(X_{ij}\)</span> is a random variable. <span class="arithmatex">\(E(\boldsymbol{X})\)</span> is defined componentwise, i.e.</p>
<div class="arithmatex">\[
E(\boldsymbol{X})= \begin{bmatrix}
E(X_{11}) &amp;\cdots &amp; E(X_{1q}) \\
\vdots &amp; \ddots &amp; \vdots \\
E(X_{p1}) &amp; \cdots &amp; E(X_{pq})
\end{bmatrix},
\]</div>
<p>and <span class="arithmatex">\(E(\boldsymbol{X})\)</span> has linearity: for constant matrices <span class="arithmatex">\(A\in\mathbb{R}^{d\times p}\)</span>, $B\in\mathbb{R}^{q\times q}, <span class="arithmatex">\(C\in\mathbb{R}^{d\times q}\)</span>,</p>
<div class="arithmatex">\[
E(A\boldsymbol{X}B + C) = AE(\boldsymbol{X})B + C.
\]</div>
<p>For random vectors <span class="arithmatex">\(\boldsymbol{X}\in \mathbb{R}^p\)</span>, its covariance matrix is defined as the <span class="arithmatex">\(p\times p\)</span> symmetric matrix <span class="arithmatex">\(Cov(\boldsymbol{X})\)</span>, given by</p>
<div class="arithmatex">\[
[Cov(\boldsymbol{X})]_{ij} = Cov(X_i,X_j).
\]</div>
<p>Similar to the covariance of random variable, we have</p>
<div class="arithmatex">\[
\begin{aligned}
    Cov(\boldsymbol{X}) 
    &amp;= E\left(\left(\boldsymbol{X}-E(\boldsymbol{X})\right)\left(\boldsymbol{X}-E(\boldsymbol{X})\right)^T\right) \\
    &amp;= E(\boldsymbol{X} \boldsymbol{X}^T) - E(\boldsymbol{X})E(\boldsymbol{X})^T.  
\end{aligned}
\]</div>
<p>From the above, we have</p>
<div class="arithmatex">\[
Cov(A\boldsymbol{X}) = A \cdot Cov(X) \cdot A^T.
\]</div>
<h3 id="multivariate-normal-distribution">Multivariate Normal Distribution<a class="headerlink" href="#multivariate-normal-distribution" title="Permanent link">&para;</a></h3>
<p>The multivariate normal distribution of a <span class="arithmatex">\(k\)</span>-dimensional random vector <span class="arithmatex">\(\boldsymbol{X}=\left(X_1, \ldots, X_k\right)^{T}\)</span> can be written in the following notation:</p>
<div class="arithmatex">\[
\boldsymbol{X} \sim \mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\Sigma}) \quad \text{ or } \quad \boldsymbol{X} \sim \mathcal{N}_k(\boldsymbol{\mu}, \boldsymbol{\Sigma}),
\]</div>
<p>with <span class="arithmatex">\(k\)</span>-dimensional mean vector</p>
<div class="arithmatex">\[
\boldsymbol{\mu}=E(\boldsymbol{X})=\begin{bmatrix}
E\left(X_1\right) \\
E\left(X_2\right)  \\
\vdots \\
E\left(X_k\right)
\end{bmatrix}
\]</div>
<p>and <span class="arithmatex">\(k \times k\)</span> covariance matrix</p>
<div class="arithmatex">\[
\Sigma_{i, j}=E\left(\left(X_i-\mu_i\right)\left(X_j-\mu_j\right)\right)=Cov\left(X_i, X_j\right), \quad \forall i,j = 1,\dots, k.
\]</div>
<p><span class="arithmatex">\(\boldsymbol{\Sigma}\)</span> is assumed to be positive definite (i.e. non-degenerate) and therefore, <span class="arithmatex">\(\boldsymbol{\Sigma}^{-1}\)</span> is also positive definite. In this case, the density of <span class="arithmatex">\(\boldsymbol{X}\)</span> is given by</p>
<div class="arithmatex">\[
p(\boldsymbol{z}) = \frac{1}{\sqrt{(2\pi)^k\det(\boldsymbol{\Sigma})}}\exp\left(-\frac{1}{2}(\boldsymbol{z}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\boldsymbol{z}-\boldsymbol{\mu})\right).
\]</div>
<p><strong>Fact:</strong> for a full-rank matrix <span class="arithmatex">\(A\in \mathbb{R}^{p\times q}\)</span> (<span class="arithmatex">\(q\leq p\)</span>) and <span class="arithmatex">\(b\in\mathbb{R}^q\)</span>, we have</p>
<div class="arithmatex">\[
A\boldsymbol{X} + b\sim \mathcal{N}_k(A\boldsymbol{\mu}+b, A\boldsymbol{\Sigma}A^T).
\]</div>
<h2 id="linear-regression">Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link">&para;</a></h2>
<p>The basic idea of linear regression is to assume that</p>
<div class="arithmatex">\[
y \approx \beta_0 + \sum_{i=1}^{p} \beta_i x_i,
\]</div>
<p>where <span class="arithmatex">\(\boldsymbol{X} = [x_1, x_2, \dots, x_p]^T\)</span> (for now we assume <span class="arithmatex">\(\boldsymbol{x}\in \mathbb{R}^p\)</span>). More precisely, we make a assumption about <span class="arithmatex">\(p(y\mid\boldsymbol{x})\)</span> as follows:</p>
<div class="arithmatex">\[
y = \beta_0 + \sum_{i=1}^{p} \beta_i x_i + \varepsilon,
\]</div>
<p>where <span class="arithmatex">\(\varepsilon\)</span> is noise with <span class="arithmatex">\(\varepsilon \sim \mathcal{N}({0,\sigma^2})\)</span> and <span class="arithmatex">\(\boldsymbol{x}\)</span> is independent of the noise. Thus, we have</p>
<div class="arithmatex">\[
y\mid \boldsymbol{x} \sim \mathcal{N}(\beta_0 + \sum_{i=1}^{p} \beta_i x_i, \sigma^2).
\]</div>
<p>We know that (under squared error loss) the oracle predictor is</p>
<div class="arithmatex">\[
E(y\mid\boldsymbol{x}) = \beta_0 + \sum_{i=1}^{p} \beta_i x_i = f^*(\boldsymbol{x}).
\]</div>
<p>The goal is to find <span class="arithmatex">\(\beta_0,\dots,\beta_p\)</span> and thus <span class="arithmatex">\(f^*\)</span>.</p>
<h3 id="rewrite-training-data-in-matrix-form">Rewrite Training Data in Matrix Form<a class="headerlink" href="#rewrite-training-data-in-matrix-form" title="Permanent link">&para;</a></h3>
<p>Assume training data <span class="arithmatex">\(\{(\boldsymbol{x}^{(i)},y^{(i)})\}_{i=1}^n\)</span> were i.i.d. generated via <a href="#linear-regression">the assumption</a> about <span class="arithmatex">\(p(y\mid\boldsymbol{x})\)</span>. To simplify the notations, we define</p>
<div class="arithmatex">\[
\boldsymbol{Y} = \begin{bmatrix} 
y^{(1)} \\
\vdots \\
y^{(n)}
\end{bmatrix}, \quad 
\boldsymbol{\varepsilon} = \begin{bmatrix}
\varepsilon^{(1)} \\
\vdots  \\ 
\varepsilon^{(n)}
\end{bmatrix}, \quad 
\boldsymbol{\beta} = \begin{bmatrix}
\beta^{(0)} \\
\vdots \\
\beta^{(n)}
\end{bmatrix},
\]</div>
<p>and design matrix <span class="arithmatex">\(\boldsymbol{X}\in \mathbb{R}^{n\times(p+1)}\)</span> given by</p>
<div class="arithmatex">\[
\boldsymbol{X} = \begin{bmatrix}
1 &amp; \left(\boldsymbol{x}^{(1)}\right)^T \\
1 &amp; \left(\boldsymbol{x}^{(2)}\right)^T \\
\qquad \vdots \\
1 &amp; \left(\boldsymbol{x}^{(n)}\right)^T 
\end{bmatrix}.
\]</div>
<p>Then training data can written as</p>
<div class="arithmatex">\[
\boldsymbol{Y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}.
\]</div>
<p>Now we want to use training data to estimate <span class="arithmatex">\(\beta_0,\dots,\beta_p\)</span> and thus <span class="arithmatex">\(f^*\)</span>.</p>
<h3 id="recap-on-likelihood-function">Recap on Likelihood Function<a class="headerlink" href="#recap-on-likelihood-function" title="Permanent link">&para;</a></h3>
<p>The likelihood function <span class="arithmatex">\(L(\theta\mid \boldsymbol{x})\)</span> illustrates the probability of <span class="arithmatex">\(\theta\)</span> given data set <span class="arithmatex">\(\boldsymbol{x} = (x_1,\dots,x_n)^T\)</span>.</p>
<p>More precisely, assume we have <span class="arithmatex">\(n\)</span> samples <span class="arithmatex">\((x_1,\dots,x_n)\)</span> observed from a distribution <span class="arithmatex">\(p_{\theta}(x)\)</span> with an unknown parameter <span class="arithmatex">\(\theta\)</span>, and our goal is to estimate <span class="arithmatex">\(\theta\)</span> using the observed data.</p>
<p>We view the observed samples are realizations of some random variables <span class="arithmatex">\(X_1, X_2, \dots, X_n\)</span>, which has a joint density function <span class="arithmatex">\(p\left(X_1, \dots, X_n \mid \theta\right)\)</span>. Given <span class="arithmatex">\(X_1=x_1, \dots, X_n=x_n\)</span>, we may consider the probability of this event being observed, which is the likelihood function (a function of <span class="arithmatex">\(\theta\)</span>) defined by:</p>
<div class="arithmatex">\[
L(\theta)=L\left(\theta \mid x_1, \dots, x_n\right)=p\left(X_1=x_1, \dots, X_n=x_n \mid \theta\right).
\]</div>
<p>Note that the likelihood function is NOT a probability density function. It measures the support provided by the data for each possible value of the parameter. If we compare the likelihood function at two parameter points and find that</p>
<div class="arithmatex">\[
L\left(\theta_1 \mid \boldsymbol{x}\right)&gt;L\left(\theta_2 \mid \boldsymbol{x}\right)
\]</div>
<p>then the sample we actually observed is more likely to have occurred if <span class="arithmatex">\(\theta=\theta_1\)</span> than if <span class="arithmatex">\(\theta=\theta_2\)</span>. This can be interpreted as <span class="arithmatex">\(\theta_1\)</span> is a more plausible value for <span class="arithmatex">\(\theta\)</span> than <span class="arithmatex">\(\theta_2\)</span>. Therefore, one approach to estimate <span class="arithmatex">\(\theta\)</span> is to choose the value of <span class="arithmatex">\(\theta\)</span> which gives you the highest probability among all possible values.</p>
<p>With the assumption that samples are drawn i.i.d., the joint probability is given by multiplied probabilities, i.e.</p>
<div class="arithmatex">\[
p\left(X_1, \dots, X_n \mid \theta\right) = \prod_{i=1}^n p_\theta\left(X_i\right),
\]</div>
<p>hence taking the log transforms this into a summation, which is usually easier to maximize analytically. Thus, we often write the log-likelihood rather than the likelihood.</p>
<h3 id="estimate-the-coefficients-beta_i">Estimate the Coefficients <span class="arithmatex">\(\beta_i\)</span><a class="headerlink" href="#estimate-the-coefficients-beta_i" title="Permanent link">&para;</a></h3>
<p>Here we find an estimate of <span class="arithmatex">\(\boldsymbol{\beta}\)</span> by maximum likelihood estimation:</p>
<p>By <span class="arithmatex">\(\boldsymbol{X}\)</span> is independent of the noise (and vice versa), we have</p>
<div class="arithmatex">\[
\boldsymbol{Y} \mid \boldsymbol{X} \sim \mathcal{N}_{n}(\boldsymbol{X}\boldsymbol{\beta}, \sigma^2I_n),
\]</div>
<p>and thus, the (log-)likelihood function is given by the density function of the above multivariate normal distribution.</p>
<p>By maximizing the likelihood function, we can estimate <span class="arithmatex">\(\boldsymbol{\beta}\)</span>:</p>
<div class="arithmatex">\[
\begin{aligned}
\hat{\boldsymbol{\beta}}
&amp;= \operatorname*{arg\, max}_\beta \ln(p(\boldsymbol{Y} \mid \boldsymbol{X})) \\
&amp;= \operatorname*{arg\, max}_\beta \left(\frac{1}{2\sigma^2} (\boldsymbol{Y} - \boldsymbol{X}\boldsymbol{\beta})^T (\boldsymbol{Y} - \boldsymbol{X}\boldsymbol{\beta})\right) \\
&amp;= \operatorname*{arg\, max}_\beta \|\boldsymbol{Y} - \boldsymbol{X}\boldsymbol{\beta}\|^2,
\end{aligned}
\]</div>
<p>which becomes a least squares problem. We take a gradient with respect to <span class="arithmatex">\(\boldsymbol{\beta}\)</span> and set the gradient for 0, and after solving for <span class="arithmatex">\(\boldsymbol{\beta}\)</span>, we have</p>
<div class="arithmatex">\[
\hat{\boldsymbol{\beta}} = \left(\boldsymbol{X}^T \boldsymbol{X}\right)^{-1} \boldsymbol{X}^T\boldsymbol{Y},
\]</div>
<p class="annotate">where we assume <span class="arithmatex">\(\boldsymbol{X}\)</span> is a full-rank matrix and thus <span class="arithmatex">\(\boldsymbol{X}^T \boldsymbol{X}\)</span> has an inverse(1).</p>
<ol>
<li>Otherwise, if <span class="arithmatex">\(\boldsymbol{X}^T \boldsymbol{X}\)</span> is not invertible, there exists <span class="arithmatex">\(v\neq \boldsymbol{0}\in \mathbb{R}^{p+1}\)</span> such that <span class="arithmatex">\(\boldsymbol{X}^T \boldsymbol{X} v = \boldsymbol{0}\)</span>, which indicates columns of <span class="arithmatex">\(\boldsymbol{X}\)</span> are linearly dependent. And columns of <span class="arithmatex">\(\boldsymbol{X}\)</span> are always linearly dependent when <span class="arithmatex">\(p\geq n\)</span>.</li>
</ol>
<p>Furthermore, we can find the distribution of <span class="arithmatex">\(\hat{\boldsymbol{\beta}}\)</span> conditional on the training features <span class="arithmatex">\(\boldsymbol{X}\)</span>:</p>
<div class="arithmatex">\[
E(\hat{\boldsymbol{\beta}}\mid \boldsymbol{X}) = E\left(\left(\boldsymbol{X}^T \boldsymbol{X}\right)^{-1} \boldsymbol{X}^T\boldsymbol{Y}\mid \boldsymbol{X}\right) = \boldsymbol{\beta},
\]</div>
<p>which indicates that <span class="arithmatex">\(\hat{\boldsymbol{\beta}}\)</span> is unbiased;</p>
<div class="arithmatex">\[
\begin{aligned}
Cov(\hat{\boldsymbol{\beta}}\mid \boldsymbol{X}) 
&amp;= Cov\left(\left(\boldsymbol{X}^T \boldsymbol{X}\right)^{-1} \boldsymbol{X}^T\boldsymbol{Y}\mid \boldsymbol{X}\right) \\
&amp;= \left(\boldsymbol{X}^T \boldsymbol{X}\right)^{-1} \boldsymbol{X}^T \cdot Cov\left(\boldsymbol{Y}\mid \boldsymbol{X}\right) \cdot \boldsymbol{X} \left(\left(\boldsymbol{X}^T \boldsymbol{X}\right)^{-1}\right)^T \\
&amp;= \sigma^2(\boldsymbol{X}^T \boldsymbol{X})^{-1};
\end{aligned}
\]</div>
<p>and therefore,</p>
<div class="arithmatex">\[
\hat{\boldsymbol{\beta}}\mid \boldsymbol{X} \sim \mathcal{N}_{p+1}(\boldsymbol{\beta}, \sigma^2(\boldsymbol{X}^T \boldsymbol{X})^{-1}).
\]</div>
<h3 id="evaluate-ols-prediction-estimate">Evaluate OLS Prediction Estimate<a class="headerlink" href="#evaluate-ols-prediction-estimate" title="Permanent link">&para;</a></h3>
<p>The above estimation is called ordinary least squares (OLS) in statistics. Now we evaluate our estimation when receiving a new data pair <span class="arithmatex">\((\boldsymbol{x_{*}},y_*)\)</span>. We make our prediction by</p>
<div class="arithmatex">\[
\hat{f}(\boldsymbol{x_{*}}) = \tilde{\boldsymbol{x}}^T \hat{\boldsymbol{\beta}}, \quad
\tilde{\boldsymbol{x}} = \begin{bmatrix}
1 \\
\boldsymbol{x_{*}}
\end{bmatrix}.
\]</div>
<p>Consider the bias of <span class="arithmatex">\(\hat{f}\)</span> (conditional on <span class="arithmatex">\(\boldsymbol{X},\boldsymbol{x_{*}}\)</span>),</p>
<div class="arithmatex">\[
E(\hat{f}(\boldsymbol{x_{*}}) \mid \boldsymbol{X},\boldsymbol{x_{*}}) = \tilde{\boldsymbol{x}}^T E(\hat{\boldsymbol{\beta}} \mid \boldsymbol{X},\boldsymbol{x_{*}}) = \tilde{\boldsymbol{x}}^T \boldsymbol{\beta}.
\]</div>
<p class="annotate">We know that <span class="arithmatex">\(E(y_* \mid \boldsymbol{x_{*}}) = \tilde{\boldsymbol{x}}^T \boldsymbol{\beta}\)</span>, and thus the OLS prediction is unbiased(1).</p>
<ol>
<li>This conclusion relied on the assumption that the data has a linear relationship. In practice, our model is only an approximation to the true distribution. So we will have bias.</li>
</ol>
<p>Now, we consider the variance:</p>
<div class="arithmatex">\[
Var(\hat{f}(\boldsymbol{x_{*}}) \mid \boldsymbol{X},\boldsymbol{x_{*}}) = \tilde{\boldsymbol{x}}^T\cdot Var(\hat{\boldsymbol{\beta}} \mid \boldsymbol{X},\boldsymbol{x_{*}}) \tilde{\boldsymbol{x}} = \sigma^2\tilde{\boldsymbol{x}}^T(\boldsymbol{X}^T \boldsymbol{X})^{-1}\tilde{\boldsymbol{x}}.
\]</div>
<p>Roughly speaking, if <span class="arithmatex">\(\boldsymbol{x_{*}}\)</span> is similar to the training data features, the variance will be small; otherwise, the variance will be large.</p>
<h3 id="interval-estimate">Interval Estimate<a class="headerlink" href="#interval-estimate" title="Permanent link">&para;</a></h3>
<p>We want to make a prediction interval for <span class="arithmatex">\(y_*\)</span> in the form of</p>
<div class="arithmatex">\[
\left[C_{low}(\boldsymbol{Y}, \boldsymbol{X}, \boldsymbol{x_{*}}),C_{high}(\boldsymbol{Y}, \boldsymbol{X}, \boldsymbol{x_{*}})\right].
\]</div>
<p>We hope <span class="arithmatex">\(y_*\)</span> to be contained in this with probability of at least <span class="arithmatex">\(1-\alpha\)</span> (usually <span class="arithmatex">\(\alpha = 0.05\)</span> or <span class="arithmatex">\(\alpha = 0.01\)</span>), i.e.</p>
<div class="arithmatex">\[
Pr\left(y_*\in \left[C_{low},C_{high}\right] \mid \boldsymbol{X}, \boldsymbol{x_{*}}\right) \geq 1-\alpha.
\]</div>
<p>Recall <a href="#linear-regression">the assumption</a> that <span class="arithmatex">\(y_*\mid \boldsymbol{\tilde{x}} \sim \mathcal{N}(\boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}}, \sigma^2)\)</span>. By</p>
<div class="arithmatex">\[
E(y_* - \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}} \mid \boldsymbol{X}, \boldsymbol{x_{*}}) = 0,
\]</div>
<p class="annotate">and <span class="arithmatex">\(Cov\left(y_*, \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}} \mid \boldsymbol{X}, \boldsymbol{x_{*}}\right)=0\)</span>(1) and thus</p>
<ol>
<li>This is because <span class="arithmatex">\(\hat{\boldsymbol{\beta}}\)</span> only depends on the training data and we assume newly received data pair is independent of training data.</li>
</ol>
<div class="arithmatex">\[
\begin{aligned}
&amp;Var(y_* - \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}} \mid \boldsymbol{X}, \boldsymbol{x_{*}}) \\
&amp;= Var\left(y_*\mid \boldsymbol{X}, \boldsymbol{x_{*}}\right) - 2 Cov\left(y_*, \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}} \mid \boldsymbol{X}, \boldsymbol{x_{*}}\right) + Var\left(\boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}} \mid \boldsymbol{X}, \boldsymbol{x_{*}}\right) \\
&amp;= \sigma^2 + \sigma^2 \boldsymbol{\tilde{x}}^T(\boldsymbol{X}^T \boldsymbol{X})^{-1}\tilde{\boldsymbol{x}},
\end{aligned}
\]</div>
<p>we know that <span class="arithmatex">\(y_* - \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}}\)</span> is still normally distributed, given by</p>
<div class="arithmatex">\[
y_* - \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}} \mid \boldsymbol{X}, \boldsymbol{x_{*}} \sim \mathcal{N}\left(0, \sigma^2\left(1+\boldsymbol{\tilde{x}}^T(\boldsymbol{X}^T \boldsymbol{X})^{-1}\tilde{\boldsymbol{x}}\right)\right).
\]</div>
<p>To obtain the interval estimation, we also need to get rid of <span class="arithmatex">\(\sigma^2\)</span> as it is unknown. Recall <a href="#linear-regression">the assumption</a> that the noise is normally distributed. We can estimate the variance <span class="arithmatex">\(\sigma^2\)</span> by the scaled residuals, i.e.</p>
<div class="arithmatex">\[
\hat{\sigma}^2 = \frac{\|\boldsymbol{Y} - \boldsymbol{X}\hat{\boldsymbol{\beta}\|^2}}{n-p}.
\]</div>
<p>Then we have</p>
<div class="arithmatex">\[
\frac{y_*-\boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}}}{\sqrt{\hat{\sigma}^2\left(1+\boldsymbol{\tilde{x}}^T(\boldsymbol{X}^T \boldsymbol{X})^{-1}\tilde{\boldsymbol{x}}\right)}} \mid \boldsymbol{X}, \boldsymbol{x_{*}}
\]</div>
<p>follows a t-distribution with <span class="arithmatex">\(n-p\)</span> degree of freedom. Let <span class="arithmatex">\(t_{n-p,\alpha/2}\)</span> and <span class="arithmatex">\(t_{n-p,1-\alpha/2}\)</span> be the <span class="arithmatex">\(\alpha/2\)</span> and <span class="arithmatex">\(1-\alpha/2\)</span> quantile of the this distribution. Denote <span class="arithmatex">\(\sqrt{\hat{\sigma}^2\left(1+\boldsymbol{\tilde{x}}^T(\boldsymbol{X}^T \boldsymbol{X})^{-1}\tilde{\boldsymbol{x}}\right)}\)</span> as <span class="arithmatex">\(C\)</span>. Then, we have</p>
<div class="arithmatex">\[
Pr\left(\frac{y_*-\boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}}}{C}\in \left[t_{n-p,\alpha/2}, t_{n-p,1-\alpha/2}\right] \mid \boldsymbol{X}, \boldsymbol{x_{*}}\right) \geq 1-\alpha,
\]</div>
<p>that is</p>
<div class="arithmatex">\[
Pr\left(y_*\in \left[C t_{n-p,\alpha/2} + \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}},C t_{n-p,1-\alpha/2} + \boldsymbol{\tilde{x}}^T\hat{\boldsymbol{\beta}}\right] \mid \boldsymbol{X}, \boldsymbol{x_{*}}\right) \geq 1-\alpha.
\]</div>
<h3 id="examples-and-discrete-features">Examples and Discrete Features<a class="headerlink" href="#examples-and-discrete-features" title="Permanent link">&para;</a></h3>
<p>So far we assume <span class="arithmatex">\(\boldsymbol{x}\)</span> lies in <span class="arithmatex">\(\mathbb{R}^p\)</span>. Here we will introduce discrete features and mixed features by giving some examples.</p>
<p><strong>Example</strong> Polynomial Regression (<span class="arithmatex">\(\mathcal{X} = \mathbb{R}\)</span>):</p>
<p>The model takes <span class="arithmatex">\(x\)</span> and transforms it to a new feature</p>
<div class="arithmatex">\[
x \mapsto (1,x,x^2,\dots,x^d),
\]</div>
<p>and the model becomes</p>
<div class="arithmatex">\[
y = \beta_0 + \beta_1x + \beta_2x^2 + \dots + \beta_d x^d + \varepsilon,
\]</div>
<p>use this new feature in a regression. For instance, assume we have 4 data pairs for training and use a 2-degree polynomial in regression: training data is given by</p>
<div class="arithmatex">\[
\begin{bmatrix}
x^{(1)} \\
x^{(2)} \\
x^{(3)} \\ 
x^{(4)}
\end{bmatrix}
= 
\begin{bmatrix}
2 \\
-1 \\
3 \\
5
\end{bmatrix}.
\]</div>
<p>We first map the following training data to the design matrix <span class="arithmatex">\(\boldsymbol{X}\)</span>, given by</p>
<div class="arithmatex">\[
\begin{bmatrix}
1 &amp; 2 &amp; 4 \\
1 &amp; -1 &amp; 1 \\
1 &amp; 3 &amp; 9 \\
1 &amp; 5 &amp; 25
\end{bmatrix}.
\]</div>
<p>The OLS estimate is still <span class="arithmatex">\(\hat{\boldsymbol{\beta}} = \left(\boldsymbol{X}^T \boldsymbol{X}\right)^{-1} \boldsymbol{X}^T\boldsymbol{Y}\)</span>. This allows us to fit <span class="arithmatex">\(y\)</span> wit ha non-linear function of <span class="arithmatex">\(x\)</span>.</p>
<p><strong>Example</strong> Categorical Feature:</p>
<p>A categorical feature could be, for instance 3 categories as </p>
<div class="arithmatex">\[
x= \left\{\begin{matrix}
1, \quad &amp;\text{ if Age} &lt;20, \\
2, \quad &amp;\text{ if } 20\leq\text{Age}&lt;40, \\
3, \quad &amp;\text{ if Age} \geq 40.  
\end{matrix}
\right.
\]</div>
<p>We transform categorical <span class="arithmatex">\(x\)</span>'s via indicator functions. </p>
<p>First way is the dummy variable method: By choosing a baseline class ( say class '3'), we transform</p>
<div class="arithmatex">\[
x \mapsto \left(1,I(x=1),I(x=2)\right),
\]</div>
<p>and the regression model becomes</p>
<div class="arithmatex">\[
y =  \beta_0 + \beta_1 I(x=1) + \beta_2 I(x=2) + \varepsilon,
\]</div>
<p>where we have <span class="arithmatex">\(E(y\mid x=3) = \beta_0\)</span>, <span class="arithmatex">\(E(y\mid x=1) = \beta_0+\beta_1\)</span>, and <span class="arithmatex">\(E(y\mid x=2) = \beta_0 + \beta_2\)</span>. </p>
<p>Another way is more symetric -- we have the model</p>
<div class="arithmatex">\[
y =  \beta_0 + \beta_1 I(x=1) + \beta_2 I(x=2) + \beta_3 I(x=3) + \varepsilon,
\]</div>
<p>where we have <span class="arithmatex">\(E(y\mid x=1) = \beta_0 + \beta_1\)</span>, <span class="arithmatex">\(E(y\mid x=2) = \beta_0+\beta_2\)</span>, and <span class="arithmatex">\(E(y\mid x=3) = \beta_0 + \beta_3\)</span>. Since <span class="arithmatex">\(\beta_0\)</span> is redundant, it can be dropped. </p>
<p>Assume we have training data: </p>
<div class="arithmatex">\[
\begin{bmatrix}
x^{(1)} \\
x^{(2)} \\
x^{(3)} \\
x^{(4)}
\end{bmatrix}
=
\begin{bmatrix}
1 \\
2 \\
3 \\
1
\end{bmatrix},
\]</div>
<p>and the corresponding design matrix is </p>
<div class="arithmatex">\[
\boldsymbol{X} = \begin{bmatrix}
1 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0
\end{bmatrix}.
\]</div>
<p><strong>Example</strong> Mixed Features</p>
<p>We can combine continous and categorical features. For instance, if <span class="arithmatex">\(x\in \{1,2,3\}\times\mathbb{R}\)</span>, we can do similar mapping:</p>
<div class="arithmatex">\[
x\mapsto \left(1,I(x_1=1),I(x_1=2),x_2,x_2^2\right). 
\]</div>
<p>Assume the training data is </p>
<div class="arithmatex">\[
\begin{bmatrix}
x^{(1)} \\
x^{(2)} \\
x^{(3)} 
\end{bmatrix}
=
\begin{bmatrix}
1 &amp; 3.5\\
2 &amp; 7 \\
3 &amp; -2.1
\end{bmatrix},
\]</div>
<p>then the design matrix is given by</p>
<div class="arithmatex">\[
\boldsymbol{X} = \begin{bmatrix}
1 &amp; 1 &amp; 0 &amp; 3.5 &amp; 12.25 \\
1 &amp; 0 &amp; 1 &amp; 7 &amp; 49\\
1 &amp; 1 &amp; 0 &amp; -2.1 &amp; 4.41
\end{bmatrix}.
\]</div>
<p><strong>Example</strong> Intersactions between Features</p>
<p>We can also have intersactions between features. For instance, if <span class="arithmatex">\(\mathcal{X}\in\mathbb{R}^2\)</span>, then we can consider thier multiplication in the mapping:</p>
<div class="arithmatex">\[
x\mapsto \left(1,x_1,x_2,x_1x_2,x_1^2,x_2^2\right). 
\]</div>
<p><strong>Remark</strong> Why don't we just use lots of features? I.e. in polynomial regression, why don't we take degree <span class="arithmatex">\(d\)</span> to be large? That is because problems owith overfitting! This is mentioned in the <a href="../stat541_week2/#illustrations-by-polynomial-fitting">variance-bias tradeoff</a>.</p>
<h3 id="variable-selection">Variable Selection<a class="headerlink" href="#variable-selection" title="Permanent link">&para;</a></h3>
<p>Assume we have many features, i.e. <span class="arithmatex">\(\boldsymbol{X}\)</span> has many columns. Given an index set <span class="arithmatex">\(I = \left(i_1,i_2,\dots,i_k\right)\)</span>, where <span class="arithmatex">\(i_1\leq i_2\leq \dots\leq i_k\)</span>, define </p>
<div class="arithmatex">\[
\boldsymbol{X}_I = \begin{bmatrix}
\mid &amp; &amp; \mid \\
x_{i_1} &amp; \cdots &amp; x_{i_k} \\
\mid &amp; &amp; \mid
\end{bmatrix}, \quad 
\boldsymbol{\beta}_I = \begin{bmatrix}
\beta_{i_1} \\
\vdots \\
\beta_{i_k}
\end{bmatrix}.
\]</div>
<p>Then we can obtain a submodel with features in <span class="arithmatex">\(I\)</span> give nby </p>
<div class="arithmatex">\[
\boldsymbol{Y} = \boldsymbol{X}_I \boldsymbol{\beta}_I + \varepsilon. 
\]</div>
<p>Because of the problem of overfitting, we may not want to use empirical risks to evaluate the submodel (the empirical risk will always decrease when adding new features). A better idea is to add a penalty for including new features: </p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \operatorname{AIC}(I) = \frac{1}{n}\left(\|\boldsymbol{Y} - \boldsymbol{X}_I \hat{\boldsymbol{\beta}}_I\|^2 + 2k\hat{\sigma}^2\right), \\
&amp; \operatorname{BIC}(I) = \frac{1}{n}\left(\|\boldsymbol{Y} - \boldsymbol{X}_I \hat{\boldsymbol{\beta}}_I\|^2 + \ln(n) k\hat{\sigma}^2\right),
\end{aligned}
\]</div>
<p>where if <span class="arithmatex">\(\hat{\boldsymbol{\beta}}\)</span> is estimated by using the full model, <span class="arithmatex">\(\hat{\sigma}\)</span> is given by</p>
<div class="arithmatex">\[
\hat{\sigma}^2 = \frac{\|\boldsymbol{Y} - \boldsymbol{X}_I \hat{\boldsymbol{\beta}}\|^2}{n-p}. 
\]</div>
<p>We want to choose proper index set <span class="arithmatex">\(I\)</span> to maximize AIC or BIC. For simplicity, we may view <span class="arithmatex">\(I\)</span> as a string in length <span class="arithmatex">\(p\)</span> consists of 0 and 1, where 0 indicates the feature is not included and 1 indicates the feature is included: for instance, </p>
<div class="arithmatex">\[
(0,1,0,0,1)
\]</div>
<p>is an index set of 5 features where the second and fifth feature are included. In this way, <span class="arithmatex">\(I\)</span> is a point in <span class="arithmatex">\(\{0,1\}^p\)</span> and we may visualize the choice of <span class="arithmatex">\(I\)</span> as picking a vertex of a hypercube. <img alt="Cube with p=3" src="../stat541_week301.svg" title="Cube with p=3" /> Minimizing AIC is the same as searching for the optimal vertex on the cube. </p>
<p>For <span class="arithmatex">\(p&gt;40\)</span>, search becomes infeasible. If we enumerate the AIC for every <span class="arithmatex">\(I\)</span>, this called best subset selection. Instead, we can do greedy search over the cube. </p>
<p>Forward selection: </p>
<ol>
<li>
<p>Start with trivial null model <span class="arithmatex">\(y = \beta_0 + \varepsilon\)</span>. </p>
</li>
<li>
<p>Add a feature by searching for the model <span class="arithmatex">\(y = \beta_0 + \beta_i x_i + \varepsilon\)</span> over <span class="arithmatex">\(i\)</span> that has the smallest AIC/BIC. Call this best <span class="arithmatex">\(i\)</span> to be <span class="arithmatex">\(i_1\)</span>. </p>
</li>
<li>
<p>Continue by find an <span class="arithmatex">\(j\)</span> where the model <span class="arithmatex">\(y=\beta_0 + \beta_{i_1} x_{i_1} + \beta_j x_j + \varepsilon\)</span> maximizes AIC/BIC. Call this <span class="arithmatex">\(j\)</span> to be <span class="arithmatex">\(i_2\)</span>. </p>
</li>
<li>
<p>Keep on doing this until we reach the full model. </p>
</li>
<li>
<p>Choose the model in our sequence with the smallest AIC/BIC. </p>
</li>
</ol>
<p>Backward selection: start at full model and remove variables until reaching the null model. </p>
<p>Best subset selection needs to fit <span class="arithmatex">\(2^p\)</span> linear models. On the other hand, for forward (backward) selection needs to fit</p>
<div class="arithmatex">\[
p+(p-1)+\dots + 1 = \frac{p(p+1)}{2}
\]</div>
<p>models, which is an order of <span class="arithmatex">\(O(p^2)\)</span> computations. </p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://discordapp.com/users/1329948280070869012" target="_blank" rel="noopener" title="discordapp.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M492.5 69.8c-.2-.3-.4-.6-.8-.7-38.1-17.5-78.4-30-119.7-37.1-.4-.1-.8 0-1.1.1s-.6.4-.8.8c-5.5 9.9-10.5 20.2-14.9 30.6-44.6-6.8-89.9-6.8-134.4 0-4.5-10.5-9.5-20.7-15.1-30.6-.2-.3-.5-.6-.8-.8s-.7-.2-1.1-.2C162.5 39 122.2 51.5 84.1 69c-.3.1-.6.4-.8.7C7.1 183.5-13.8 294.6-3.6 404.2c0 .3.1.5.2.8s.3.4.5.6c44.4 32.9 94 58 146.8 74.2.4.1.8.1 1.1 0s.7-.4.9-.7c11.3-15.4 21.4-31.8 30-48.8.1-.2.2-.5.2-.8s0-.5-.1-.8-.2-.5-.4-.6-.4-.3-.7-.4c-15.8-6.1-31.2-13.4-45.9-21.9-.3-.2-.5-.4-.7-.6s-.3-.6-.3-.9 0-.6.2-.9.3-.5.6-.7c3.1-2.3 6.2-4.7 9.1-7.1.3-.2.6-.4.9-.4s.7 0 1 .1c96.2 43.9 200.4 43.9 295.5 0 .3-.1.7-.2 1-.2s.7.2.9.4c2.9 2.4 6 4.9 9.1 7.2.2.2.4.4.6.7s.2.6.2.9-.1.6-.3.9-.4.5-.6.6c-14.7 8.6-30 15.9-45.9 21.8-.2.1-.5.2-.7.4s-.3.4-.4.7-.1.5-.1.8.1.5.2.8c8.8 17 18.8 33.3 30 48.8.2.3.6.6.9.7s.8.1 1.1 0c52.9-16.2 102.6-41.3 147.1-74.2.2-.2.4-.4.5-.6s.2-.5.2-.8c12.3-126.8-20.5-236.9-86.9-334.5zm-302 267.7c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.4 59.2-52.8 59.2m195.4 0c-29 0-52.8-26.6-52.8-59.2s23.4-59.2 52.8-59.2c29.7 0 53.3 26.8 52.8 59.2 0 32.7-23.2 59.2-52.8 59.2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/shx-haah" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.indexes"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>